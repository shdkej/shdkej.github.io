---
title   : 아키텍처
summary :
date    : 2021-05-20 20:33:31 +0100
updated : 2021-10-21 00:34:51 +0900
tags    : develop
---

## 아키텍처 :define:
> 정책과 세부사항으로, 룰과 가이드를 구분
> 아키텍처의 목표는 정책과 세부사항을 적절히 구분해 세부사항의 결정은 최대한 미룰
> 수 있게 하는 것
>> 클린 아키텍처

과한 추상화는 실체가 없다는 느낌을 줄 수 있겠다.

어디까지 추상화를 할지는 어떤 목적으로 프로그램을 만드느냐에 따라 조정된다

모든 것이 추상화되고 가변적일 필요는 없다
- 언어를 넘어서는 추상화
    - 포팅을 쉽게 할 정도의 추상화

[[Think#러셀과 화이트헤드]]

#### 한 서비스의 구조 :example:
계산 중심 구조(cpu) vs 데이터 중심 구조

#### 프로젝트 아키텍처
넷플릭스 모델 - 전체가 하나로 묶여있다
네이버 모델 - 각 역할별로 분리되있다
리디북스 모델 - 데이터가 묶여있다

#### 그동안의 아키텍처 모델
- 3 layer
- MVC - MVVC - MTV
- 네트워크 레이어
- 12 Factor app
- MSA
- DDD
- JAM stack
- [Clean Architecture](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)
- SOA

그리고
- 육각형 아키텍처
- DCI data, context, interface 제임스 코플리언
- BCE bounded control entity
- https://ahnheejong.name/articles/package-structure-with-the-principal-of-locality-in-mind/
- https://mingrammer.com/translation-structuring-applications-in-go/
- https://geminikim.medium.com/지속-성장-가능한-소프트웨어를-만들어가는-방법-97844c5dab63
- https://overthecode.io/the-meaning-and-limits-of-atomic-design-from-a-software-design-perspective/

#### 모놀리스도 정반합에서 합이었던 아키텍처
- [ ] 어떤 것을 보완하기 위해 모놀리스라는 아키텍처가 달성되었을까
3 layer 아키텍처를 만들다보니 모놀리스가 된 것인가

#### 일관성이 중요한 것 같다.
각 회사마다 저마다의 아키텍처가 있어서 개발자는 그 아키텍처를 파악해야한다.
그렇다면 한 부분을 알았을 때 다른 부분도 그와 비슷하거나 일관성이 잘 유지되어
있는 구조라면 쉽게 익힐 수 있다. 어떤 아키텍처인지는 그 다음 문제인 것 같다.
일단 일관성이 있으면 가독성이 올라가고, 이것이 소프트웨어를 좋게 만들어준다.

#### library
모든 코드를 라이브러리화 하면 각 라이브러리를 호출하는 어댑터를 만들게 되고 너무
비대해진다.
그렇다고 어댑팅 안하면 라이브러리 수정 시 여기 저기서 바꿔야 된다.
그렇다고 라이브러리를 일관된 형태로 유지하자면 그것도 쉽지 않다

lib1
- file

source1
- main
- lib1-adapter

source2
- main
- source1-adapter
- lib1-adapter

이런 구조가, 라이브러리 변경 시

lib1
- file-v2 // 변경

source1
- main
- lib1-adapter // 변경

source2
- main
- source1-adapter
- lib1-adapter // 변경

수정이 전체에 영향을 미치면 안된다.

#### 개발 시작
1. 가장 간단한 실행을 위한 설계
2. 폴더 만들기
- note

3. 구현해야 하는 것 적고 결과값 적기
- note/main_test.go

4. 테스트 통과시키기
- note
  -  main.go
  -  main_test.go

5. 기능 추가를 위해 설계
6. 파일 추가
7. 반복

그러다가 어느 시점이 되면 아래 정도의 복잡성이 생긴다
note
- logic1
  - main.go
  - data.go
  - adapter.go
- logic2
- api
  - http.go
  - grpc.go
- lib

이런 구조에서 더 복잡성이 필요해지면 분리하기 좋다는 신호다

그래서 저 코드 구조가 반복되면 확장이 된다
인프라는 저 구조를 쉽게 컨트롤하도록 구성된다

인프라 - 서비스 - 데이터의 구조로 한 인프라가 구성되고
이것이 다시 프렉탈로 반복된다

인프라에서 api, logging를 지원해주면 더 좋겠다

#### code design
main - 메인에서 동작만 나타낸다. 구현은 다른 파일에서 한다
```
func main() {
  init()
  get()
  set()
  health()
  doSomething()
}
```
http_server - http로 렌더링하는 작업만 수행한다
logic - 인터페이스를 받아서 인터페이스를 구현한다
```
type s struct {

}
func (s struct) init() {

}
```

#### 외부 라이브러리 분리
외부 라이브러리를 분리하려고 하는데, 그러면 폴더 구조가 어떻게 되는거지
- cmd
- lib1
- ilb2
- logic1
- logci2

이런 식으로 되는 건가

- cmd
- logic1
  - lib1
  - lib2
- logic2
  - lib1
  - lib2

이것보다는 나은 것 같은데 위의 구조에서 라이브러리와 메인 로직의 구분이 안된다

- cmd
- logic1

일단 내 로직이 메인이다
cmd에서는 이를 한 눈에 보기 좋게 한다
여기서 이제 라이브러리가 들어간다

- cmd
- logic1
  - db_logic
- db

이렇게 하면 메인에서 구현에 필요한 것을 db에서 받아서 실행하도록 해야한다

외부 라이브러리가 여러 개 중에 하나를 선택할 수도 있다

- cmd
- logic1
  - db_logic
- db
  - redis
  - RDBMS

이렇게 하려면 db를 다시 추상화해야한다

...
- db
  - redis/
  - RDBMS/
  - db.go

근데 이렇게 하면 외부 라이브러리를 구현하는 작업이 다시 되야 되서 별로다

클라이언트 프로그램은 마이크로서비스일 필요 없을 거 같다?

메인은 전체 흐름
에러 처리는 내부에서 처리?
메인 파일은 의미가 있어야 하고, 세부 구현은 적지 않도록...
```
func main() {
    if err := initHTTPServer(); err != nil { log.Println(err) }
    if err = addHealthCheck(); err != nil { log.Println(err) }
    if err = addLogic(); err != nil { log.Println(err) }
    if err = addLoggig(); err != nil { log.Println(err) }
    if err = runHTTPServer(); err != nil { log.Println(err) }
}
```

#### 아키텍처를 만들면서 구체적인 예제를 적으면서 해본다 :행동:
도메인 로직
유닛 함수
외부 함수
통신 로직

데이터 불러오는 곳도 각 서비스마다 구현을 해야하는데, db 종류에 상관없이
받아들이는 부분도 있어야하는데.. 그러면 데이터베이스 쪽만 2단계가 되서 마음에
안든다

#### library 호출
마이크로서비스의 library를 한곳에 모아서 보여주고
쉽게 호출해 쓸 수 있도록 해야한다.
어떻게?

#### 마이크로서비스도 인터페이스를 만족하도록 구성하는 것이 좋겠다
우리 회사의 api는 다른 기능이라도 같은 방식으로 동작합니다 라고 알려주면
사용자가 다른 서비스에도 쉽게 접근할 수 있겠다

스테이징 서버 테스트 시 본 서버의 데이터를 그대로 가져오면 너무 사이즈가
커지니까 필요에 따라 기간을 정해서 가져올 수 있도록 구현하면 좋을 것 같다

#### 설정가능해야하고 플러그인 방식으로 동작

#### create project
git init
remote add
add secret
add hooks
add workflows

#### 프로젝트를 모듈로 구성
모듈은 한 팀의 인원정도만 사용
기존 데이터 이용 필요시 CQRS를 응용해서 데이터쿼리용 저장소를 이용

도메인의 스펙을 분석해서 적용하는 작업이 계속 될 수 있어야 한다


각 프로젝트마다 모듈로 구성
모듈의 개수는 팀원의 수 정도
기존의 데이터가 필요하면 어떻게 가져오나
CQRS를 응용해서 공통 데이터 저장소를 따로 둔다


람다로 함수들을 만들어서 gcp와 aws에 이중화하고
로컬 서버에서 로드밸런서로 비용안들게 호출하도록 할 수 있을까

호출횟수를 모니터링해서 로드밸런서가 확인하도록

메시지큐에서 실패한 것들을 받으면 람다를 실행하게 해서 오류처리 할 수 있다

각 세부 폴더에
메인로직, 데이터, 유닛, api를 넣으면
mvc 패턴에서 구현하는 것을 모두 구현할 수 있나?

#### 인프라 개발자의 관점에서 3 요소
인프라 - 데이터 - 서비스

서비스 안에는 백엔드, 프론트, 디자인, 기타 등등이 또 따로 있을 것이다
모든 요소에는 QA와 테스트가 있고
인프라에는 시큐리티, 로깅 등등이 있고

그러면 인프라 관점이 아니라 소프트웨어의 관점으로 봐도 될까

#### code logic
레고모델로 모듈화 진행
입력 로직 출력의 형태

레고모듈이 완벽한건 아니지만 괜찮은 모델이다

부족한 부분
유기적인 얽힘이 되면 좋겠다

json으로 입력받아 json으로 출력
http response로 출력

api gateway에서 이걸 처리하고

로직은 json만 대응하도록
로직에서는 내가 필요한 데이터가 있는지 확인하는 발리데이션을 해서 로직 수행

json으로 필터링 해서 결과값 보내주는 어댑터(플러그인) 만들어서 쓰면 좋겠네

grpc로 이걸 하면 proto 파일에 모델, 함수 적고, 구현파일을 만들면 이런 형태가
만들어 질거 같다.
여기에 grpc gateway를 써서 http로 받을 수 있게 하고, documentation 되는지 확인

#### input, logic, output의 구조
go-kit, gRPC도 이런 구조로 구성하려고 했다. 이 방법이 먹히는 것 같다.
openfaas도 request, response 구조

#### api는 연결부위 설계를 잘 해야겠다.
input값, output값
- 메인로직을 만들고 컨테이너화해서 배포하면, 사이드카가 api routing해주고,
  데이터 보관하도록 만들고 싶다. 메인로직의 input과 output만 잘 유도하면 될 것
  같은데, fastapi와 python 머신러닝 api화 해주는 서비스가 있던데 확인해봐야겠다.

#### 데이터 확장 모듈
아이디를 같이 쓰고 추가 데이터를 붙여서 호출할 수 있도록 하면 마이크로서비스에서
데이터형식을 좀 더 자유롭게 쓸 수 있지 않을까

블록들을 모아서 전체를 구성하는 것이 좋다
재사용성이 늘고, 확인할 지점이 적절한 양이다. 작은 문제부터 접근하기 좋다.
근데 블록들이 다 제각각이면 챙겨야하는 지점이 늘어난다.
가져온 블록의 내부가 복잡하면 조치하기 힘들다. 간단한 것들로 많이 붙이면 겉잡을
수 없이 커져서 오히려 하나 하나 확인할 수 없다

점진적으로 변화할 수 있는 데이터 저장소가 있으면, 일단 저장해놓고 점점 살을 붙여
나중에 잘 써먹을 수 있다

지역성의 원리로 캐싱을 하면 이전 작업과 거리가 있는 작업을 하게 되면 캐싱을 새로
해야한다. 이 점을 보완하고 싶다

#### business logic
비즈니스 로직의 함수는 추상적이어야 하지만
세부 구현도 비즈니스 로직에 들어가야 한다.
외부 라이브러리에 비즈니스 로직이 안들어가기 때문에.
함수 구현은 추상적으로 하고 test code로 세부를 테스트하면 될까?
세부 구현은 어디서 해야하지?
인터페이스에 추상이 남아있고, 구현은 세부적으로 하면 될까

#### api
| api | -- | business logic | -- | data crud
            | business logic2 |
            | 3               |
            | 4               |
            | 5               |
이렇게 구성 되있다
data crud는 공통 로직으로 쓰는 역할(share library)
비즈니스 로직에서는 api로 crud를 제어한다.
aggregation api를 따로 만든다
data crud는 index단위로 같은 로직으로 여러개를 만든다
grpc로 만들어서 쓴다
컴퓨팅 로직은 서버리스로 배포해서 api로 쓴다
인프라 코드가 각 비즈니스로직을 접근할 수 있도록 사이드카를 장착한다

데이터베이스 crud 서비스로 레포지토리를 모을까?
호출할 때는 어떻게 구분하지?

![msa](./img/msa.png)

#### 레고형 아키텍처 :module:
레거시를 계속 쓰려고
모듈화의 좋은 방법이라 생각
응답과 결과의 형태를 통일해서 쉽게 교체가 가능할 것 같다
처음에 완벽한 형태를 짜는 것이 불가능하기 때문에 변화하기 쉬운 형태로 짜놓는다. 공통된 방식을 쓰면 변경이 쉽지 않을까.

Mysql tip 글에서 DB에서 지나친 추상화를 하지 말라는 조언이 있었다.

비즈니스 로직에서 추상화를 어디까지 하는게 좋을까

#### 기능을 잘게 쪼개면 전체를 조망하기 쉬워지지 않을까 :module:
기능이 커지면 분리하는 방식은
새로 접근하는 사람이 기능을 파악하는데는 도움이 될 수 있지만 하나를 파악해도 파악하지 못한 나머지 기능들이 많아서 너무 많아 질리거나 본질에 접근 못한다는 느낌을 받을 수 있겠다
'그건 내 잔상이다' 의 반복 같은 느낌

#### 데이터 저장소는 Bigquery이고 이를 불러오는 것은 다른 툴에서 할 수 있다
툴을 다른걸 쓰더라도 데이터는 같은 것을 쓸 수 있도록 할 수 있다

#### 전체적인 그림
큰 그림 > 작은 그림

아키텍처 구축의 목표점은 없다
**좋은 기준점을 만들어서 그 기준점을 계속 개선해나가는 것이 최선**
- 이런 관점에서 쿠버네티스, react, graphql, backend를 어떻게 구성해야하나?
- 정책과 세부사항이 너무 많으면 기준점을 잘 지켜나갈 수 있을까?

선택과 집중
유연하고 융합적인 환경
두 가치를 어떻게 잘 융합할 수 있을까

분산화 하는 것이 시대의 흐름
심플하게 유지
- 0에서 10은 심플이 아니다. 100에서 10이 심플
제한이 필요하다

[[Standard]]
[[Decision]]
[[#분산]]

#### 한 아키텍처에 너무 많은 것을 넣으려고 하다가 이도저도 아니게 되겠다
처음에 집중할 목표를 잡고 작게 작게 처리해 나가야 하겠다 :행동:

개인이 제작하는 프로그램에는 규모의 한계가 있다
프로토타입 수준의 프로그램이 제작될 따름인데 개인 프로젝트의 의미는 무엇일까?
스스로 기술 발전을 할 수 있다. 기술 발전을 해서 무엇을 하나. 기술 협력을 통해 기술 발전에 기여한다
회사가 아닌 다른 기술 발전 기여 통로를 만들어야겠다

작은 양의 코드를 수정하는데도 정리가 안되어 무엇을 건드려야 할지 막막해지는
순간이 있었다. 작은 크기로 함수들을 쪼개놓았는데 그 함수들이 여러개가 되다 보니
길을 잃은 것 같다. 어떻게 길을 찾아야 할까

-----------------------------------------------------------------------

## 확장성
50 유저를 상대로 운영하고 있지만 10만 유저를 상대할때도 문제가 생기지 않게
염두에 두고 수정한다. 하지만 임시방편으로 해결할 때도 있다.
그런 임시방편을 잘 리스트화해서 처리를 잘 해야겠다

단일고장점이 없는 아키텍처라면
새로운 기술을 도입하는 것이 쉽게 될 수 있겠다

hdd로 구축된 서버에서 한대만 ssd로 교체해서 상황을 지켜보고, 문제가 있어도 다른
서버에서 커버할 수 있다면 문제점 파악하는데에 도움이 되겠다

소프트웨어 자체의 에러가 전체에 영향을 미치지 못하도록 하면 다른 것으로 교체하면
그만이라서 관리하기 쉽겠다

3대의 서버를 켜놓고 1대씩 리부팅을 해도 나머지 2대가 있어서 괜찮다면 오래 켜놔서
생기는 문제를 막을 수 있듯이
일부러 1대씩 계속 재부팅되도록 하고, 상태저장이 필요 없도록 하면 os의 문제에서
조금은 자유로워지지 않을까
재부팅하면 캐시가 다시 쌓여야하는 부분은 확인해봐야겠다

3대의 서버를 한 묶음으로 추가 자원이 필요하면 이 묶음이 여러개가 되도록 하면
확장성 문제도 해결되지 않을까?
쿠버네티스에서는 이를 지원해준다

쿠버네티스는 고가용성, 확장성, 배포를 바로 할 수 있게 해줘서 좋다
서버는 필연적으로 고가용성과 확장성과 배포가 필요하다
추가로 모니터링, 로깅도 세트다

#### portable, universal
새로운 기술이나 지식을 얻었을 때 우리의 업무에 바로 적용할 수 있는 자유로움

회사의 상황에 맞추기보다 표준에 맞추는 방향

데이터베이스를 커스터마이징하기보다 어댑터를 이용해 원본은 잘 지켜나가서 새로운
것이 생겼을 때 바로 도입할 수 있는 환경

#### 변하는 것과 변하지 않는 것 :vs:collection:
변하지 않는 것은 없지만 빠르게 변하는 것과 천천히 변하는 것은 나눠져 있다
아키텍처를 구성할 때 천천히 변하는 것을 잘 분리하여 빨리 변하는 것에 더 집중하고
천천히 변하는 것은 잘 유지할 수 있도록 하면 좋겠다

아이폰의 뒷면

#### 소프트웨어는 언제까지 확장되는게 좋을까
무한정 소프트웨어가 비대해지면 관리도 힘들고, 또 그렇게 커질 필요도 없다
네이버에서는 검색 기능은 다른 기능과 분리되어 있고, 팀도 따로 분리되어 있다.
회사 팀 구조도 개발팀을 다른 팀과 분리하는 경우도 있고,
기능별로 개발,디자인,기획을 같은 팀에 구성하는 경우도 있을텐데,
어떤 경우에 어떤 구성이 좋을까

-----------------------------------------------------------------------

## 분산
1인가구, 마이크로 서비스 아키텍처, 블록체인의 탈중앙화가 닮은 것 같다
탈중앙화
분산화
민주주의
분산 서비스
고가용성
마이크로서비스
조직 구조도?

확장은 필연적으로 복잡성을 만든다

#### 이동통신 시스템이 분산 처리 시스템에서 잘 돌아가고 있는 사례인 것 같다
데이터베이스의 레플리카 기능과 샤딩
일라스틱서치
하둡

#### Multi Processing
분산 시스템의 고민과 비슷한 고민이 멀티 프로세스를 사용하려는 시도에도 있겠다.

MPI라는 인터페이스가 있다.
- https://operatingsystems.tistory.com/entry/High-Performance-Computing-MPI
- http://hpcschool.kr/usc/wp-content/uploads/sites/10/2014/04/MPI.pdf

Apache의 MPM

#### 분산 개발 환경의 해결책으로 ci가 나왔다
분산 서비스간의 통합도 ci 같이 할 수 있을까

일단 데이터를 통합하는 서비스를 이용한다던가

#### 계층적인 것과 분산된 것
중첩
폴더 안에 폴더를 두는 구조는 유용하지만 복잡해져서 별로 안좋은 것 같다
그래서 프로젝트 사이즈도 폴더 중첩이 없는 정도로 나누고 싶은데
그러다보면 작은 덩어리가 많아져서 어디에 무엇이 있는지 모를 수 있겠다
그래서 정돈이 필요한데, 이 정돈을 어떻게 할 수 있을까

트리 구조의 깊이가 깊어지는 것과 넓이가 넓어지는 것은 비슷한 복잡도인가?

넓이가 넓어져서 관리가 힘들 상황을 생각해보면, 놀이터가 넓으면 선생님이 주변에
있는 아이가 아니면 어떤 일이 벌어지는지 알 수 없다

복잡성을 염두에 두고 미리 뼈대를 만들어 놓는 것보다, 작게 분리하는 것이 복잡성을
컨트롤 할 더 나은 방법 같다.
자바의 폴더구조가 처음부터 중첩된 폴더를 미리 만들어 놓는 방식인데, 이런 부분이
거슬린다. 폴더 안에 폴더가 들어가면서 깊어지면 컨트롤이 어려워질 것 같다.

- 근데 go standard layout 에서 cmd 폴더 안에 메인 함수들을 폴더로 구성하게 하는
것을 추천해서 자바와 비슷한 구조를 베스트 프렉티스로 했다. 복잡한 서비스에서는
중첩이 최선인가. 3단 중첩은 필요한가

[[About_Development#module]]

#### 확장 -> 모듈
각 서비스가 많은 트래픽을 감당할 수 있어야 하고,
분산 처리 시스템처럼, 묶였을 때 트래픽 처리가 선형적으로 증가 되야 한다

쉽게 교체할 수 있는 모듈의 형태로 구성되야 한다. 하지만 쉽게 교체할 수 있다는
것이 진리는 아니다.

기능별로 팀이 구성되 있을 때 그 팀에 오래 있던 사람이 나가고 새로운 사람이
들어오면 새로운 사람이 대체하려면 아주 힘들다. 애초에 대체는 안되고 다른 역할이
되겠지만.
메뉴얼이 쌓여있어도 기존 작업을 100% 알 수 없다.
기능별로 집중했기 때문에 깊고 많은 내용이 섞여있고, 그래서 기능적으로
성숙해졌지만 새로운 사람에게는 따라가야 할 길이 멀어진다.
이게 경험의 차이라고 불리워지는 것인 것 같다.
기능별 팀에서의 문제가 아니라 인간세상의 문제였다.

기능의 깊이가 어느정도 깊어지면 다시 분리해야 한다.
근데 사람의 수는 한정적이어서 분리가 안된다

#### 마이크로서비스의 해법을 다른 분산 시스템에서 얻고자 한다
전체를 퉁쳐서 하나로 규정하려는게 아니라
기존의 문제점들을 확인하고 어떤 해법들이 있었는지 정보를 얻기 위해서

#### 라즈베리파이
라즈베리파이를 여러 대 두면 라즈베리파이가 하나씩 고장날 때마다 고쳐야 한다는
의미도 된다.
데스크탑 하나만 쓰면 전체가 한번에 관리된다.
물론 라즈베리파이 쪽이 싸게 처리되지만, 100대가 있을 때 매번 고치기는 힘들 것
같다.

대신 라즈베리파이 하나가 고장나도 시스템은 그대로 유지될 수 있다는 장점이 있다.

-----------------------------------------------------------------------

## micro service
- every node make end-point, http, grpc
    - need documentation
- flexible micro service
    - it can be split and compose
- logging and visualization

#### microservice
- 마이크로서비스에서 문제가 생긴 지점을 바로 확인할 방법은?

#### 마이크로 서비스
라이브러리를 쓰듯이 다른 서비스들을 사용하면 성능 상의 손해가 있다
마이크로아키텍처는 관리할 지점이 늘어나는 단점이 있지 않나

- 메시지 기반의 비동기 통신
- 사가 패턴 - 데이터 일관성 유지를 위해
- 도메인 주도 설계
- 이벤트 소싱 패턴

- API
- 서비스 메시
- 서비스 디스커버리
- 메시지 처리
- 서킷 브레이커

- API gateway, 서비스 메시, 서비스 디스커버리 차이는?
  - 서비스 메시 안에 서비스 디스커버리가 보통 내장되있다
  - api gateway는 외부에서의 접속, 서비스 메시는 내부의 네트워크 관리

왜 마이크로 서비스인가
- 마이크로 서비스를 위해서는 필연적으로 서비스 간 커뮤니케이션이 필요하고,
  비동기 통신과 동기 통신을 잘 구분해서 사용해야 한다.
  - 동기는 API를 이용해서, 비동기는 메시지 큐를 이용해서.
  - 각 서비스 간 데이터를 메시지 큐에 발행하고 구독하는 식으로 데이터 공유,
    이벤트 처리가 가능하다.
- 마이크로 서비스를 일일이 관리하기 보다 서비스 디스커버리를 이용해서 자유롭게
  생성과 운영이 되게 해야겠다
- 단일고장점이 없도록 노드를 여러 개 두어 관리하는 것이 좋겠다.

- 큰 팀을 작은 팀으로 나누면 팀 간 대화에 장벽이 생기고, 안개가 생긴다. 다른
  팀의 영역에는 안들어가려고 하고, 그 쪽에서 일어난 일이 전달이 안될 때가
  많아진다. 어떻게 이 장벽을 없앨 수 있을까
- 핵가족에 이어 1인가구가 늘어남에 따라 대가족일 때는 자연스럽게 알 수 있던
  것들이 이제는 공부를 해야 알 수 있게 되었다.
- 수평적인 연결망이 만들어져서 정보공유를 할 수 있게 해야한다. 회사에서 팀장이
  있고 팀장회의를 하는 것과 비슷한 느낌이지만 수평적인 관계의 연결망으로.
  (현재의 커뮤니티가 이 역할을 하고 있는 것일까? Web 2.0)

#### 서비스메시
규칙기반의 부하분산으로
배포(테스트에 배포)와 릴리즈(프로덕션에 배포)를 분리하기 좋다고 한다

텔레메트리 관리
- 네트워크 트래픽 관련 지표 수집 및 추적

#### SOA, MSA, DDD
service oriented architecture
- 중간에 enterprise service bus를 둬서 서비스 간 공유를 하려고 했으나, 당시
  시대상 팀 구조가 변화에 재빠르게 대응하지 못했고, MSA와 비슷한 목표를 가졌으나
  성공하지 못했다.
- MSA의 핵심은 통신 처리이고, 이 처리 흐름을 만들어내는 서비스 메시가 등장했다.
  마이크로 서비스는 서비스의 수가 많고, 이를 관리하는 방법이 필요하다

#### event driven architecture
- in micro service, each service need send some event.
- if not implement event, can parse some data?
- http server <- event producer -> queue
  DB
  lambda
- lambda can assign http or sqs. how to get data?

#### banksalad github
- awesome style이라는 레파지토리로 사내 행동강령을 모아놓았다. awesome
- python template을 만들어 사용하고 있다

이렇게 회사 내 자료들을 메타적으로 관리하는 레포지토리를 만들어서 관리하면
좋겠다.
사내 인적 리소스 관리도 git으로 하면 좋겠다

#### microservice experience
- [배민](https://www.youtube.com/watch?v=BnS6343GTkY)
    - 결제 장애 시 결제만 장애나는 환경을 원했다.
    - 모놀리스 서버 테이블이 700개... >> 분리 후에도 한 서비스에 테이블이 많이
      있을 것
    - 이벤트 기반으로 하니 훨씬 효율이 증가했다.
- [11번가](https://www.youtube.com/watch?v=J-VP0WFEQsY)
    - Spring cloud 이용

#### 마이크로서비스
어차피 한 사람이 모든 마이크로서비스를 관리할 수 없다?
그래서 모놀리스에서 서로 엮여있던 것을 마이크로화해서 편하게 관리할 수 있게
하는거지 마이크로서비스를 무한정 많이 만드는 것이 목적은 아닐 것이다.
한 사람이 다루는 서비스를 제한 해주는 것이 좋겠다.

#### 마이크로서비스에서 유저 정보 가지고 작업하는 법
유저 정보 유지해서 계속 불러오는 효율적인 방법은?

모놀리스에서 함수호출을 이벤트 드리븐이 대체했을 때 고속처리가 가능한가? 배민은 되긴 하나보다
- 같은 네트워크에 있다면 rpc로 서비스가 나눠져 있으면 rpc로 데이터를 취합해 api gateway가 모은 데이터를 리턴해주면 된다

쿠버네티스에서는 RBAC가 어느 순간에 동작하는거지?

#### 메시지 큐
sqs에 실패처리용 큐를 하나 만들어서 거기에 담아서 에러를 확인한다

#### junk food
넷플릭스가 마이크로서비스를 하면서 느꼈던 개발의 주요 문제점

dependency
- circuit breaker 로 의존성 있는 서버가 죽는 것에 대응

Scale
- EVCache

Variance

Change

#### Observability를 높이기 위해서는 어떻게 해야할까
이 문제가 발생했는지를 내가 설정하지 않아도 알 수 있으려면 바로 observability가 필요하다
- 피드백을 받기 위해
- 문제가 일어나기 전에 예측하기 위해?
- 분산 환경에서 모니터링이 한눈에 되어야 한다
- Metrics, Events, Logs, Traces 를 한눈에 확인한다
- 예측하지 못한 문제를 찾으려고 한다
- [제어이론](https://ko.wikipedia.org/wiki/제어이론)에서
  **관측 가능성(observability)**이란, 시스템의 **출력 변수(output variable)**를
  사용하여 **상태 변수(state variable)**에 대한 정보를 알아낼 수 있는지를
  나타내는 용어이다. 시스템의 출력 변수를 사용하여 특정 상태 변수에 대한 정보를
  알아낼 수 있을 때 그 상태 변수는 **관측 가능하다(observable)**고 하며,
  시스템의 모든 상태 변수가 관측 가능할 때 그 시스템은 관측 가능하다고 한다.
- 메트릭이란? 최적의 네트워크 경로 또는 측정 가능한 단위(평가지표)

서버를 가상화해서 사용 시 서버는 추상화가 되고 서버의 상태를 일일이 확인할 필요가 없다. 문제가 생기면 없애고 새로 만들면 되기 때문에.

근데 문제가 생겼는지 확인하려면 기준점이 있어야 하고, 기준이 설정되어 있지 않다면 문제가 발생했는지 알 수 없다

정상 상태를 정의하고, 비정상 상태로 만든 후 정상 상태로 돌리는 것을 통해
Observability를 높인다.
이것을 카오스 엔지니어링이라고 한다.

예측하는 것이 아니라 관찰할 수 있도록 만든 후 관찰 하는 것.

- Observability
- post mortem
- 무엇을 보여줄 수 있는가
- 무엇을 해결해야 하는가
- 어떤 문제가 생길 것 같은가

#### architecture process organization
![triangle](img/triangle.png)
출처: https://kihoonkim.github.io/2018/03/25/Microservices%20Architecture/first-msa-retro/

#### When many people come to site. how to keep working server
1. allow maximum people, others redirect to queue.
2. scale out

#### 섀시
에러 체크, 로깅, 헬스체크, 회로 차단 등 마이크로서비스에 필요한 것들을 만들어놓은 것을 이용하자는 마이크로서비스 섀시라는 개념이 이미 있었다
go-kit, micro 참고
- 외부화(엔드포인트 적용)
- 헬스체크
- 모니터링 지표 뽑기
- 서비스 디스커버리
- 회로 차단
- 분산 추적
- 로깅(액션 기록)
- 보안
이 기능들을 메인로직에 적을 필요없이 섀시를 적용시키면 자동으로 기능이 수행된다

그리고 서비스 메시는 섀시의 진화 형태가 될 것인데, 현재는 일부 기능만 구현하고 있고, 아직 완전 대체제는 아니다
istio, linkerd

istio에서 분산 추적을 하려면 app: deployname 을 라벨링 해줘야 한다

#### 마이크로서비스에서 두 서비스에서 불러온 데이터를 어떻게 합칠까
두 서비스면 그냥 호출하는데서 부르면 되겠지만
rdbms에서 하던 조인처럼 자유자재로 하기에는 성능이 안나온다

CQRS의 쿼리를 이 상황에 쓰던가
아니면 쿼리를 모아서 rdbms로 모으는 추가적인 리소스를 이용해서 해결?

#### CQRS
쿼리와 커맨드를 분리했다.
쿼리는 CRUD의 Read의 개념이고
커맨드는 나머지 CUD의 개념이다.
Read를 조합해서 나머지 명령을 하는 경우가 많고,
Read 작업이 다른 작업과 사용되는 빈도에도 차이가 있기도 하다.
마이크로 서비스에서 특히 다른 DB에서 가져올 때 조합하기 위해 이렇게 분리하면 좋을 것 같다

이 개념에서는 애초에 모델, 서비스 자체에서 쿼리와 커맨드를 분리해서 다른 서비스로 만들라고 한다

사가
애그리거트
쿼리
api

log data 나 db table 등을
초기에 설계해서 쭉 써야하는 것보다는
변경에 유연했으면 좋겠다
변경에는 근거가 필요하지만, 실제로 변경할때는 쉽게 할 수 있도록
마이그레이션이 쉽지 않다

변경에 유연한 것들은 무엇이 있을까


관리요소가 많아지면 일관성이 깨지기 쉽다
마니크로서비스는 내 생활방식과 다르다

코드가 많아지면 고쳐야하는 지점이 늘어난다


마이크로서비화도 무한정 많이 할게 아니라 탈출지점을 만드는게 좋겠다
한 팀이 감당할 서비스를 생각해서


분산 데이터
분산 서비스
분산 환경을 컨트롤하는 게 필요하다

복잡성도 분산 환경에서 있고 분산이 곧 개별적인 인간 세상과 닮은 소프트웨어의 구조


마이크로서비스의 경계설정
데이터 쿼리 트랜잭션
데이터 모아서 처리하기

마이크로서비스는 데이터가 뿔뿔이 흩어져있다고 느낄 수 있다
신경써야할 요소가 많아진다고 볼 수 있다
넷플릭스는 이것을 어떻게 관리하지?

모놀리스로 개발하다보면 기존에 것에 계속 추가해야하고 수정해야한다.
새로운 기능이 필요하면 기존 구조를 건드려야 할 수도 있다
이것을 막기 위해 마이크로서비스를 쓰지만
관리포인트는 줄일 수 있어야 한다.

#### 마이크로서비스
포인트
- 단일 고장 지점을 없앤다
- 의존 영역을 분리한다
- 빠르고 가벼운 사이즈를 유지한다

이를 어렵게 하는 요소
- API endpoint가 많아져서 이를 일일이 관리하기 힘들어 API Gateway라는 것을 이용하려 하는데 이 API gateway가 단일 고장점이 되버린다
- 흩어져 있는 데이터 여러개를 합쳐서 사용해야 할 경우가 있다
- 처음에는 작은 사이즈지만 요구사항이 늘어남에 따라 사이즈는 필연적으로 커진다.

이에 대한 마이크로서비스의 대응방법
- sidecar 패턴으로 API gateway를 없애고 각 서비스에 연결점을 붙인다
- SAGA, CQRS
- 사이즈가 커지면 다시 분리한다.

#### 마이크로서비스
미이크로서비스간 데이터 통합과 작업 일관성 유지를 위해 다른 서비스가 필요한데
이를 커밋과 적용으로 나누는 방식으로 할 수 있고
사가 패턴을 이용해 해결할 수도 있다

#### microservice
쿠버네티스의 구조처럼 마이크로서비스를 구현하면 되지 않을까

데이터를 다 분리해놓고 중앙에 모아서 처리하다가 요청이 자주 오간다 싶으면
연결하는 길을 추가?

한 마이크로서비스의 단위를 로직 - 데이터베이스 - 사이드카로 놓고 사용
이 마이크로서비스를 관리하는 툴을 생각해본다

중앙에 데이터들이 하나로 묶인다
한 마이크로서비스에 요청이 오면 그 응답으로 메시지를 보낸다
메시지는 중앙, 관리자에게 전달되고, 관리자는 피드백으로 중앙에는 업데이트로
이용된다

#### 마이크로서비스 잘 구축해보고 싶다 (이벤트 처리)
카프카 이용하는 마이크로서비스 예제 보고싶다
- github.com/gilbutITbook/007035
- github.com/gilbutITbook/006947

#### micro crud
service - crud-service - extension

crud : api <- logic <- library

crud를 해주는 엔드포인트만 나와있고, 내부는 감춰진다
엔드포인트가 정해져있으면, 나머지끼리 통신하는데 이용한다
logic이 api안에 포함되고, logic은 api를 몰라도되고, 외부 라이브러리를 통한
구현도 로직을 모르게 한다. 일방통행

crud 모델을 일반화해서 범용적으로 쓸 수 있도록 하고, extension을 붙여 확장한다
ID, Name, Date, Content, Tag 로 구성하고, Content에 다시 내용을 구겨넣는다.
필요한 곳에서 알아서 쓴다?

#### microservice
한 부분의 변화를 위해 다른 부분을 신경 쓰지 않아야 한다.
한 부분의 변화가 다른 부분에 영향을 주지 않아야 한다.

kubernetes로 여러개의 서비스로 쪼개면 microservice인가?
micro로 서비스를 만들면 microservice인가?
monolith와 구분되는 microservice의 특징은 각 서비스가 개별 데이터베이스를 갖는
것인데, micro는 어떤 구성 방식인가

-----------------------------------------------------------------------

## Devops
what is benefit of devops
- makes team source useful.
- developer think only source version control system(git, etc)
- easy deploy, easy rollback, feedback

DevOps' goal is for a small team of developers to implement functions
independently, verify accuracy in a production-like environment, and distribute
code quickly and securely to the production environment.

DevOps gonna make fast to deploy
SRE gonna maintaining production to reliability

Devops goal
* Build automation
* Quickly release
* Test automation
* Feed back

[[Software#Devops came from agile 2009]]
[[Information#데브옵스의 목표는]]

데브옵스는 린, 에자일의 연장선
예전에 제품 출시까지 오래 걸리고 회사 전체가 움직이던 것이 리스크가 있고
느려서 시대에 뒤처진다는 것에서 대응

개발과 운영을 분리된 것이 아니라 제품 출시에 있어서 같이 진행되어야 하는 것으로 보고 통합하는 문화

각 팀으로 분리하는 것이 아니라 같은 팀으로 묶여서 협업하는 문화
- 개발자가 운영도 하는 업무의 확장으로 느끼지 않고, 제품 전반적인 관리를 참여하는 문화가 되도록 해야겠다
- 사용자와 interaction을 늘리는 것인데, 현실적으로 개발자가 마케팅을 같이 하는 것은 무리가 있다. 개발과 마케팅의 간극을 줄이고, 응집력을 높이게 하는 것이 DevOps engineer의 역할일 것 같다.

인프라, CI/CD 파이프라인을 구성 및 관리하고 개발을 편하게 하기 위한 도구들을 개발하고 관리하는 포지션
- 개발자들이 개발에만 집중하고 빠르고 편하게 개발할 수 있도록 돕는다
- 개발자들이 개발에만 집중하지만 고객과의 interaction은 가깝게 느낄 수 있도록 한다.

사람과 사람을 장벽 없이 연결 시키는 작업
- 제품 개발에 참여하는 인원들 간의 장애물을 낮추기 위해 노력

데브옵스는 다른 영역도 취미로 하는게 좋겠다
다른 작업을 편하게 해주는게 대브옵스의 목표라고 생각.

가볍고, 의존성 없고, 쉬운 설정 및 이동이 가능하며, 피드백 루프를 개발 프로세스에
잘 녹여내는 시스템 구축을 지향하며, 개발에만 집중할 수 있는 환경을 만들기 위해
 고민하고 있습니다.

사용자가 신뢰할 수 있는 제품 경험과 개발자가 신뢰할 수 있는 개발환경 구축을
만들고 싶습니다.

확장하기 쉽고 자동화 된 개발 환경을 구축해 개발 시에는 서버 신경 안쓰고 쉽게
배포할 수 있도록 구성하려 하고 있습니다.

- 사용자에게 바로 영향이 가는 서버를 운영할 때 데브옵스는 어떻게 해야 할까
- 데브옵스는 포지션으로서 존재할 필요가 있는가?
- 데브옵스는 qa엔지니어와 가깝나 백엔드와 가깝나

작은 기업에서는 기획,개발,qa,데브옵스를 나누지 않을 것이고
규모가 커져야 qa엔지니어의 필요성을 느끼는 듯하다
서버가 코드화되면서 개발자가 서버를 관리하기 쉬워졌다
그래서 백엔드가 서버도 관리할 수 있게 되었는데 백엔드와 데브옵스를 분리할
필요가 있을까?
프론트가 nodejs와 함께 백엔드를 할 수 있게 되었는데 그런 풀스택 개발자는
엔터프라이즈에서도 먹히잖아?

규모가 커짐에 따라 세부적으로 역할을 나누는 것이 일반적이지만
데브옵스는 엔지니어의 역할 확장으로서 존재해도 되지 않을까?
프론트든 백엔드든 qa이든 서버가 어차피 코드화되어 있다면 같이 신경쓰는게 오히려 관리가 쉽지 않을까?
세분화되고 분리되면 고도화하기 좋긴 하겠다

개발과 운영의 통합은 종속성, 의존성이 아니라 조화다
각 마이크로 서비스도 데이터영역과 서비스 영역이 서로 의존하는게 아니라 조화를 이루게
하면 되겠다

#### DevOps한 백엔드를 위한 개발환경구축 가이드
필요한 리소스
- github repository + github flow
- minikube + 주소를 secret에 입력
- cookiecutter
- 개발 폴더

얻게 되는 것
- CI/CD
- monitoring
- logging
- security
- image

cookiecutter
- ci/cd pipeline
- ansible script
- grafana prometheus
- fluentd
- traefik
- some yaml for kubernetes

좀 더 생각해볼 것
- CoC 를 위해 설정을 쉽게 할 방법
    - 사용자 스펙을 읽어서 없으면 서버 스펙을 사용한다.
    - 서버 스펙은 사용자가 건드리지 않게 한다.
    - nagios도 이렇게 되있었고, vim이나 zsh등 커맨드라인 툴들도 이렇게 되있다.
      odoo도 파일을 만들어서 오버라이드 되게 해놨지만 기존 코드를 바로 건드릴
      수는 있었다.
- 내가 kustomize를 안쓰고 싶어하는 이유가 기존의 리소스를 활용하지 않고 독자적인
  것으로 만들어져서 너무 국소적이고, 나만 쓰게 될 것 같고, 새로운 것을
  외워야하는 느낌이 들어서인데, 회사용 툴을 만들게 되면 이런 느낌을 주지 않을까
- cookiecutter를 인프라용 레포지토리 템플릿으로 만들어서 쓰면 편하지 않을까
    - 프로젝트 생성 시마다 레포지토리를 만들 수도 있지만, 참조해서 쓸 수도
      있어야 할 것 같다. 즉, cookiecutter를 쓰지 않더라도 한 번 구축해놓은
      인프라를 다른 서비스를 개발할 때도 쓰도록 하는 것이 좋을 것이다.
    - 간단한 커맨드라인 툴을 만들어서 레포지토리의 버전을 읽어와서 적용하고 추가
      설정파일로 CoC가 되면 되겠다. 근데 이 커맨드라인 툴을 조심히 만들어야겠다.
    - CI workflow로 툴을 실행시키고 설정파일이 따로 없으면 내 인프라
      설정파일을 보도록?
    - 각자 설정해야만 하는 것: 서버 주소
    - 서비스 종류는 docker를 읽으면 되지 않을까
- 프론트엔드는 lerna, package.json 으로 create-app -> code -> ssg build -> deploy
  프로세스가 잘 돼있다.
    - 배포처(ex. netlify)에서 github 주소만 넣으면 끝이다.
- 개발 프로세스 전체 과정이 설정파일 하나로 파악되면 좋겠다.
- 기본 테스트 프로세스는 무조건 실행하도록 default로 돼있고, 추가로 원하는
  테스트도 할 수 있도록 돼야한다.
- private github 대신 github 같은 것을 실행하도록 해서 주소도 자동으로 얻게
  하려면 -> 개발자 간 공유가 힘들긴 하겠다.
- 일단 코드로 시스템을 구성할 수 있으면 어떻게든 변환할 수 있다.

#### process 그 다음을 생각해야겠다
- [ ] 개발자들의 퍼포먼스를 올리기 위해서 어떤 작업들이 필요할까
    - 이슈트래킹 서비스에 링크와 작업내용을 적고 github과 연동되어 github을
      안들어가고 이슈트래킹 서비스에서 인터랙티브하게 동작되면 좋지 않을까
- [ ] 옵저버빌리티를 어떻게 올려서 업무에 도움이 되게 할 수 있을까

#### 기업들이 데브옵스 채용 후의 상황 변화된 사례나 데브옵스들의 경험담을 보고싶다 :experience:
https://www.theteams.kr/teams/522/post/63940
- 데브옵스 채용이라기 보다는 문화를 바꾼 후 코드 관리에 집중함으로써 품질을
  높였다.

https://blog.kmong.com/크몽-모바일-데브옵스-960627d053cf?gi=c89f3ade7b36
- 경험보다는 어떤 것들을 하고 있는지 잘 정리돼있다.

https://www.bucketplace.co.kr/post/2020-07-23-오늘의-집사-서버-개발부터-운영까지-전부-다-맡겨-devops팀-리더-쟈니/
- 데브옵스 팀의 리더의 이야기

https://www.itworld.co.kr/news/155512

#### 이상적인 개발 프로세스
- 새로운 이커머스 시스템 요청이 들어왔다
- 기존의 라이브러리를 블럭처럼 추가해서 구현한다
- 약간의 업데이트가 필요해서 업데이트를 한다
- 이전의 소스에는 영향이 없다

#### 프론트와 백엔드의 협업은 어떻게 진행되지?
컨테이너로 각자 띄워서 하나? 그러면 백엔드가 업데이트되면 프론트는 언제 올리지?
클라이언트에서 graphql로 호출하는데,
데이터는 어디서 가져오나 - 테스트용 데이터를 고정해놓고 쓰나
- 그래서 CI가 나왔짜나
- 개발자가 docker compose를 다룰줄 알아야하겠다

#### 프론트엔드 서비스를 통합 포인트로 설정할 수 있나?
프론트엔드에서 마이크로서비스를 호출해서 인터랙티브할 수 있나?

네이버 검색 영역은 메인페이지와 분리되있지만 화면에는 같이 보인다. 이처럼
프론트엔드에서 호출할 수 있나?

#### 퀵 픽스와 롤백
퀵 픽스는 불합리한 것 같다
급하게 고쳐야한다면 다시 또 문제가 생길 수 있고
간단하게 고쳐진거라면 단계를 건너뛰고 올릴게 아니라 그냥 일반적인 플로우대로
진행하면 될거 같다
서버에 있는 걸 직접 고치는 것은 요즘에는 잘 안하니까...

큰 릴리즈를 했는데 에러가 발견되서 예전으로 되돌릴 수 없을때 퀵픽스를 하려고
하겠다
큰 릴리즈를 하고 처음에는 괜찮았다가 뒤늦게 문제가 발견되면 롤백보다는 빨리
조치를 하는게 낫겠다

#### 자주 쓰는 모듈을 이용해 프로젝트 진행 시 쓰게 되면
쓰면서 개선한 부분이 이전 프로젝트에 적용되야 할 수도 있고 안되야 할 수도 있다
- [ ] 전체 적용되도록 형태를 잡는다면 이전의 프로젝트에 적용하는 방법은?

#### 프로젝트 시작 시 꼭 필요한 것
모델 정의

모델 정의한 것을 서버리스로 배포.
그러면 각 모델의 연결은 어떻게?
람다로 한다면 제품 등록은 하나의 모델에 업데이트 하면 되는데, 불러올 때는 정보들이 묶여있는 상태로 불러야 호출 횟수를 줄일 수 있다.
근데 또 등록할 때 유저의 상태도 업데이트 하려면 등록도 두 개의 호출을 해야하긴 한다

#### server architecture to using some company service :행동:
특정 서비스에 종속되는 것을 조심하고 다양한 기술을 써봐야겠다
처음에는 특정기술에 의존하는 것이 영속성이 없어서 서버아키텍처에 포함하면 안되지
않을까 싶었지만 기술적으로 파악하고 사용하고 종속되지 않도록 해야겠다
앞으로도 새로운 기술을 계속 써야하기에 지금 있는 기술을 두루두루 다뤄봐야겠다
그러나 내 서버 아키텍처는 단순하고 가벼웠으면 좋겠는데 여러 기술을 사용하면
복잡해질 수 밖에 없는데 이를 계속 생각하고 있다

#### serverless
데브옵스를 문화로써 받아들인다면.
모두 serverless로 만들어서 마이크로서비스화하는게 서버관리 리소스를 없앨 수
있고,
그럼에도 서버가 필요한 작업은 모놀리스하게 만든다.
중앙 집적 리소스 서버에서 모든 자원을 관리한다.

서버가 필요한 작업
- 데이터베이스에 접근
- api 핸들링 (클라이언트에서 가능할듯)
- 모니터링?

람다의 약점
- 느린 시작
- 모노리스에 비해 통신의 비용이 든다(마이크로서비스라면 비슷)

로컬 테스트와 배포된 람다 간에 연결성을 높여보도록 구성해봐야겠다

#### serverless
serverless에 배포 전 로컬 테스트.
배포 후 자동 테스트
배포 후 에러 처리

#### Migration to own devops pipeline
1. Check Github repository
2. Dockerization
3. Manual test
4. Make CI test pipeline
5. Make package
6. Make kubernetes environment
7. Deploy pipeline
8. Make feed back loop
9. Make everything to automation

#### without stage server
I want to make only 2 stages environment
development & production

what is problem
- staging server need exist?
- production safe
- production server has problem
- managing critical data
- real world simulation

if in kubernetes. staging server is not problem. just one more pods?

is it over-resource?
CD pipeline can replace staging server?

- gitflow
- master, dev, release, stage, hotfix -- too much
- dev, test, stage, prod -- too much
- multi stage is require?

can parsing data from every node?

## SRE
To upgrade site reliability
1. Monitoring
    * Monitoring various content
    * Make automation
2. Performance check

Quick recovery scenario
* Check error 5xx, when error occurred rollback to prev version. And reporting error situation. Which are link, behavior, data, code line, build package, (commit source)

-----------------------------------------------------------------------

## Deploy

#### infra와 source를 분리
쿠버네티스 테스트 레포지토리와 myspace 레포지토리를 분리하고
Myspace의 폴더가 곧 프로젝트 목록이 되도록 구성

1. Basic 폴더를 만들어서 이를 복사해서 쓰도록한다
2. Argocd에서 폴더를 등록한다
3. 배포 완료

인프라 코드도 개발자가 관리하도록 하기 위함.
개발 코드는 컨테이너 이미지 배포하기까지 자동

Prefix로 infra 서비스와 비즈니스 서비스 구분

argocd를 github action에서 실행한다면
소스코드와 인프라코드가 분리되있는데
소스코드 변경을 인프라가 어떻게 알아차릴 수 있지?

소스코드 변경 후 인프라를 다시 건드리면 안된다
인프라는 인프라대로 관리되고, 소프트웨어 업데이트는 소스코드에서 따로 처리되야 한다

인프라 변경 시 변경될 것은 쿠버네티스 셋팅, 서버 셋팅
소스 변경 시 변경될 것은 소프트웨어 버전, 세부 설정

둘 다 쿠버네티스 어플라이를 해야되는 건 같다.

인프라 생성 시 argocd 등록 되도록 하고, 그게 소스코드를 보도록 하면 될까?
1. 레포지토리 생성
2. 도커 빌드
3. 인프라 레포에서 폴더 생성
4. argocd 싱크 등록을 1 레포지토리로 등록
5. 레포지토리 업데이트
6. argocd 동작

#### deploy
서버의 kube config를 가져온다 - private key를 github secret에 등록시키고 scp를
이용한다
변경된 파일을 인식해서 apply 한다

1. 인프라에서 추가를 하면 서비스에 설정파일을 주입한다.
2. 서비스에서 간단한 파일이라도 추가해서 신호를 준다
- 관건은 서비스를 업데이트 했을 때 따로 설정 없이 인프라가 알아챌 수 있는지인데
- cron을 계속 한다? 무리...
    - argocd도 근데 레포지토리를 cron하는 방식 아닌가?
- argocd로 배포를 하면 처음 등록만 수동으로 해주면 된다.
- kubernetes를 워크플로우에서 동작하면 argocd 필요 없다
- argocd가 소스코드 변경을 보는게 아니라 yaml 파일을 보는거라...

지금은 일단 elasticsearch에 dockerfile 빌드할 때 synonym 파일을 집어넣었다
이러면 github과 연동이 안되어서 버전 업데이트 할 때 날아간다.
대응 방법을 생각해야 한다
쿠버네티스 로컬에서 볼륨을 만들어서 연결해도 github에 업데이트는 못한다
cron으로 파일을 파싱해야 할까. 매일 한번씩 카피해서 올려도 될듯

kubernetes 같은 네임스페이스에서 연결하는 방법은?
서비스로 클러스터 ip는 오픈
서비스 이름으로 인식은 한다.
그러면 서버에서 호스트 명을 서비스명과 맞춰줘야 한다.

#### argocd
terraform 으로 master ip 얻어서 argocd 마스터로 전달
인프라 레포에서는 생성만 하고, 싱크는 argocd가 github을 보면서 할 수 있나?

서비스 레포에서 푸시 -> 도커 이미지 변경 -> 인프라 레포에서 변경 인식
-> argocd sync
- 소스 레파지토리에서 인프라 레파지토리의 버전값을 변경하고 푸시하는 방식으로
사용하더라

- argocd에서 kubernetes.local로 접속하는게 어디?

#### 배포
스테이징 서버 없이 카나리로 테스트
실제환경에서 카나리 테스트

데이터에 문제 생길 것에 대비해서 업데이트 시 스냅샷을 찍어놓고 찍은 후 생긴
데이터를 따로 더할 수 있게한다
문제가 생기면 스냅샷으로 롤백하고 추가된 데이터를 더한다

스냅샷과 데이터복구가 잘 되는지 검증한다

#### canary release
카나리 배포를 할 때 프로덕션에 할 게 아니라 내부 서버로 카나리를 해놓으면
검사하기 더 수월할까?
프로덕션에서 테스트하는 것이 내부에서 보는 것과 차이가 없을까?
프로덕션에서의 환경을 봐야하기 때문에 프로덕션을 봐야할까?

#### 스테이징 대신 카나리로 직접 테스트
그러면 카나리 하다가 전체가 문제가 생기면 어떻게 하냐는 걱정 생긴다

격리를 잘 하고, 고가용성을 챙기고
데이터 변경으로 인한 영향이 없도록 해야한다


먼저 쿠버네티스, 깃헙을 이용해 개발하다가
팀이 따로 분리되어 전문화 되면 비로소 자체 시스템이 필요하지 않을까

처음에는 여러 역할이 한 팀에 있고, 이 팀들을 관리하는 팀이 있는 구조에서
팀을 관리하는 팀을 관리하는 팀이 필요해지는 시점 정도부터 세부적인 팀의 분리를 하던가, 상위팀이 하위 팀을 위한 툴을 개발하는 팀으로 역할을 하던가 하면 되지 않을까

#### 다른 버전을 사람들이 쓰면 문제가 생긴다
특히 db 처리에서 차이가 있으면 그렇겠다
롤링업데이트는 괜찮은게 맞나?
- 어댑터 패턴이라는 것이 있다
  점진적 업데이트 시 이전 버전의 데이터를 갖고 있다가 출력을 바꿔주는 식

카나리를 먼저 하고 롤링 업데이트를 하면 되지 않을까?
db 같은 업데이트는 카나리로 하는게 좋겠다

-----------------------------------------------------------------------

## clean architecture :input:book:
> 수많은 유형의 프로그램을 개발했지만 그 시스템들은 근본적으로 비슷한 아키텍처를 공유하고 있었다. 소프트웨어 아키텍처의 규칙은 다른 모든 변수에 독립적이다.
    (독립적이다는 말은 그 프로그램에 종속되거나 의존하는게 아니라 어떤 프로그램이든 상관 없다는 뜻이다.)
> 소프트웨어 아키텍처의 목표는 필요한 시스템을 만들고 유지보수하는 데 투입되는 인력을 최소화하는 데 있다.
- 개발의 생산성을 코드 라인 수로 측정한 것은 아쉽다.
회사가 커지면 제품도 커지고 그에 따라 팀이 개편된다. 이 때 소프트웨어도 같이 팀의 크기에 맞춰 조절이 가능해지면 좋겠다.
> 회사에서 이전에 급하게 지은 코드를 나중에 고치는 일은 있을 수 없다.
> 소프트웨어를 만든 이유는 기계의 행위를 쉽게 변경할 수 있도록 하기 위해서다. (중략) 다시 말해 변경하기 쉬워야 한다.
javascript에서 npm에 코드를 배포해서 관리하는 것처럼, 회사에서 모든 코드를 저장소에 저장해놓고 사용하는 쪽에서도 쉽게 업그레이드해서 공유할 수 있으면 좋겠다.
> 각 패러다임(구조적, 객체 지향, 함수형)은 프로그래머에게서 권한을 박탈한다.
- 패러다임들의 개념이 생긴 순서가 구현된 순서와 반대라는 점과 그 생긴 것이
  58~68년에 걸쳐있다는 점, 그리고 새로운 무엇인가를 제시한 것이 아니라 오히려
  제한을 했다는 것이 충격적이다. 이 세 가지 패러다임 외에는 더 나올 것이 없다고
  보는 것도 놀랍다.
다익스트라는 공리, 정리, 따름정리, 보조정리로 구성되는 유클리드 계층구조를 프로그래밍에 이용하고자 했다.
> 뵘과 야코피니는 모든 프로그램은 순차, 분기, 반복이라는 세 가지 구조만으로 표현할 수 있다는 사실을 증명했다.
- 다익스트라가 구조적 프로그래밍을 생각한 계기는 모듈을 기능적으로 분리하기 위함이다.
- goto문은 해당 모듈이 올바르지 않다는 증명을 할 수가 없다고 한다. 다익스트라가
  유클리드 계층구조를 구현하려는 시도는 실패했지만, goto문 없이 코드가 구현
  가능하다는 것을 통해 부정확함에 대한 증명은 가능하다는 것을 알게 되었고,
  그래서 작은 모듈이 부정확하지 않다는 입증이 되지 않았다면 이는 쓸만한 모듈이
  되고, 이런 모듈들을 모아 소프트웨어 구조를 만들 수 있다는 것이 구조적
  프로그래밍의 핵심이었다.
- 수학적 증명은 참이라는 것이 증명되야 하지만, 과학적 증명은 반례를 들 수 없으면
  참이라고 인정하는 방식으로 동작하는데, 구조적 프로그래밍은 이렇게 수학적
  증명은 실패했으나 과학적 증명의 방식으로 동작할 수 있게 되었다. 그래서 각
  모듈은 쉽게 반증이 가능하도록 만들기 위해 (테스트하기 쉽도록) 만들어야 한다는
  놀라운 통찰이다. 내가 지금까지 객체 지향으로 설계하고 있다고 생각한 것들
  대부분이 구조적 프로그래밍에 해당하는 것이었다. TDD 마저도 구조적
  프로그래밍에서 이미 이야기가 되었던 것이었다.
> 정책과 세부사항을 구분한다.
- 변하지 않을 것과 변할 것을 정해본다.
- 격리된 부분과 외부 통신용 부분을 따로 관리할 수 있을까
> 시스템에서 서로 결합되지 않는 계층
  UI, 도메인에 관련된 업무 규칙, 애플리케이션에 관련된 업무 규칙.
> 다른 이유로 변경되는 것. 유스케이스
1. 처음에는 한 서버 안에 웹서버와 데이터베이스가 있다.
2. 좀 커지면 웹서버와 데이터베이스가 분리된다.
3. 그 다음은 로드밸런서가 들어오고 웹서버와 데이터베이스 묶음이 복사된다.
4. 그리고 추가적인 보조도구들이 점차 더해진다.
5. 그 다음은 웹서버가 각 기능별로 분리된다.
6. 그 기능은 다시 데이터베이스와 하나로 묶이고, 분리되고, 확장된다. 순환 구조가
   완성되었다.
- 그렇다면 웹서버를 기준으로, 확장성을 가진 구조를 만드려면 데이터베이스와
  연결이 되야 하고, 웹서버가 복사되어도 똑같은 동작을 해야하고, 외부 장치와
  연결이 쉬워야 한다. 그리고 각 기능의 분리가 된 이후에도 같은 동작을 해야한다.
- 쿠버네티스는 웹서버와 데이터베이스를 쉽게 연결시키고, 웹서버의 복사도 되고,
  외부 장치와의 연결은 데이터베이스와 연결과 다르지 않게 관리할 수 있다.
- 기능 분리 시 데이터베이스 분리도 쉽게 되야 한다.
- 보조도구들이 인프라에서 쉽게 관리되야 한다.

나중에 처리하겠다고 하고 작성한 코드는 안좋은 레거시의 예
- 나중에 레거시를 보고 한숨을 내쉬며 처음부터 다시 짜는게 낫다고 생각이 드는데, 그래봤자 똑같은 일을 반복할 뿐이다. 지금부터 나은 코드를 쌓으려고 노력하고, 이전의 코드를 리팩토링을 계속 하는 것이 더 효과적이다.
- 물론 처음부터 잘 짜여진 프로그램도 있을 수 있지만 조건이 많이 필요하다. 잘 짜여져서 같이 오랫동안 일한 동료와, 적절한 마감시간, 지식의 공유가 잘 되어있는 상태, 구성원들의 공감 등등.

-----------------------------------------------------------------------

#### 중심만 남긴다
개발 로직, 중앙 문서 관리 서비스, 코드 저장소, 데이터 저장소

#### api check
메인 함수에 어떤 api 사용하는지 나타내는 방식으로 해서
서버에 올릴 때 메인 함수의 api 응답 시간을 확인만 하면 되도록 하면 좋겠다
프로젝트 메인이 아니라 라이브러리 메인을 체크해야겠다

#### 모놀리스에서 다른 모듈 간 데이터 불러올 때 임포트 해서 함수로 호출한다
마이크로서비스에서 api로 호출하는게 일반적이겠지만
임포트 라이브러리를 만들어서 직접 api에 접근하는게 아니라 라이브러리를 통해서 접근하게 하면 전환이 쉬울 것 같다

Product
Purchase

Purchase
Import product
Product = product.getName
Purchase.product = Product

근데 내부 서비스는 외부와 격리되있고
조합해서 호출하는건 별개의 서비스에서 했으면 좋겠다
그러면 호출은 어디서 하지?

#### 외부 라이브러리 분리
어차피 외부 라이브러리가 이상이 생겨 못쓰게 되면
새로운 라이브러리에 맞게 구현해야한다

그러면 외부 라이브러리 분리는 한 곳에서만 수정하도록 모으는 역할인가?
그렇다면 외부라이브러리 안에 내부 구현을 호출하도록 해도 되겠다.
내 코드에서 외부라이브러리를 호출하던 것을
외부 라이브러리 구현 코드에서 내 코드를 호출하는 것으로
왜냐하면 http를 쓰려다 보니 내 구현에서 http동작을 호출하는 것이 과한 추상화
같았고, 구현하기도 매끄럽지 않았다

메인로직을 서버에서 호출해서 쓰는지
메인로직에서 서버로직을 호출해서 쓰는지 잘 결정해야한다

http 서버가 grpc 클라이언트도 해야한다

#### husky를 쓰면 git hooks를 github에서 공유할 수 있다
근데 이것을 쓰면 써야하는 도구가 늘어남을 의미한다

#### api pipeline
- [ ] 유닉스의 파이프라인처럼 api를 파이프라이닝 해서 원하는 값을 만들어도 괜찮을까

함수형 프로그래밍을 이용해서 파이프라이닝 형태로 만들어주는 api를 만들어서 api로 api를 불러서 파이프라이닝 하는 것.
